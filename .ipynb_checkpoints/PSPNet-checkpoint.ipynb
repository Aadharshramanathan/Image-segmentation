{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GpdXEZVHXzmt"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.layers import Convolution2D,BatchNormalization,ReLU,LeakyReLU,Add,Activation\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D,AveragePooling2D,UpSampling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ncrm4fVT-b3c"
   },
   "outputs": [],
   "source": [
    "train_folder=\"/content/drive/MyDrive/Colab_Notebooks/train\"\n",
    "valid_folder=\"/content/drive/MyDrive/Colab_Notebooks/val\"\n",
    "\n",
    "def get_images_masks(path):\n",
    "    names=os.listdir(path)\n",
    "    img_g,img_m=[],[]\n",
    "    for name in names:\n",
    "        try:\n",
    "          img=cv2.imread(path + '/' + name)\n",
    "          img=cv2.normalize(img,None,0,1,cv2.NORM_MINMAX,cv2.CV_32F)\n",
    "          img=img[:,:,::-1]\n",
    "          img_g.append(img[:,:256])\n",
    "          img_m.append(np.reshape(img[:,256:],(256*256*3)))  \n",
    "          del img\n",
    "        except:\n",
    "          print(name)\n",
    "    del names\n",
    "    return img_g,img_m\n",
    "        \n",
    "train_imgs,train_masks=get_images_masks(train_folder)\n",
    "valid_imgs,valid_masks=get_images_masks(valid_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XNBj1KX0-pAm"
   },
   "outputs": [],
   "source": [
    "def conv_block(X,filters,block):\n",
    "    # resiudal block with dilated convolutions\n",
    "    # add skip connection at last after doing convoluion operation to input X\n",
    "    \n",
    "    b = 'block_'+str(block)+'_'\n",
    "    f1,f2,f3 = filters\n",
    "    X_skip = X\n",
    "    # block_a\n",
    "    X = Convolution2D(filters=f1,kernel_size=(1,1),dilation_rate=(1,1),\n",
    "                      padding='same',kernel_initializer='he_normal',name=b+'a')(X)\n",
    "    X = BatchNormalization(name=b+'batch_norm_a')(X)\n",
    "    X = LeakyReLU(alpha=0.2,name=b+'leakyrelu_a')(X)\n",
    "    # block_b\n",
    "    X = Convolution2D(filters=f2,kernel_size=(3,3),dilation_rate=(2,2),\n",
    "                      padding='same',kernel_initializer='he_normal',name=b+'b')(X)\n",
    "    X = BatchNormalization(name=b+'batch_norm_b')(X)\n",
    "    X = LeakyReLU(alpha=0.2,name=b+'leakyrelu_b')(X)\n",
    "    # block_c\n",
    "    X = Convolution2D(filters=f3,kernel_size=(1,1),dilation_rate=(1,1),padding='same',kernel_initializer='he_normal',name=b+'c')(X)\n",
    "    X = BatchNormalization(name=b+'batch_norm_c')(X)\n",
    "    # skip_conv\n",
    "    X_skip = Convolution2D(filters=f3,kernel_size=(3,3),padding='same',name=b+'skip_conv')(X_skip)\n",
    "    X_skip = BatchNormalization(name=b+'batch_norm_skip_conv')(X_skip)\n",
    "    # block_c + skip_conv\n",
    "    X = Add(name=b+'add')([X,X_skip])\n",
    "    X = ReLU(name=b+'relu')(X)\n",
    "    return X\n",
    "    \n",
    "def base_feature_maps(input_layer):\n",
    "    # base covolution module to get input image feature maps \n",
    "    \n",
    "    # block_1\n",
    "    base = conv_block(input_layer,[32,32,64],'1')\n",
    "    # block_2\n",
    "    base = conv_block(base,[64,64,128],'2')\n",
    "        # block_3\n",
    "    base = conv_block(base,[128,128,256],'3')\n",
    "    return base\n",
    "\n",
    "def pyramid_feature_maps(input_layer):\n",
    "    # pyramid pooling module\n",
    "    \n",
    "    base = base_feature_maps(input_layer)\n",
    "    # red\n",
    "    red = GlobalAveragePooling2D(name='red_pool')(base)\n",
    "    red = tf.keras.layers.Reshape((1,1,256))(red)\n",
    "    red = Convolution2D(filters=64,kernel_size=(1,1),name='red_1_by_1')(red)\n",
    "    red = UpSampling2D(size=256,interpolation='bilinear',name='red_upsampling')(red)\n",
    "    # yellow\n",
    "    yellow = AveragePooling2D(pool_size=(2,2),name='yellow_pool')(base)\n",
    "    yellow = Convolution2D(filters=64,kernel_size=(1,1),name='yellow_1_by_1')(yellow)\n",
    "    yellow = UpSampling2D(size=2,interpolation='bilinear',name='yellow_upsampling')(yellow)\n",
    "    # blue\n",
    "    blue = AveragePooling2D(pool_size=(4,4),name='blue_pool')(base)\n",
    "    blue = Convolution2D(filters=64,kernel_size=(1,1),name='blue_1_by_1')(blue)\n",
    "    blue = UpSampling2D(size=4,interpolation='bilinear',name='blue_upsampling')(blue)\n",
    "    # green\n",
    "    green = AveragePooling2D(pool_size=(8,8),name='green_pool')(base)\n",
    "    green = Convolution2D(filters=64,kernel_size=(1,1),name='green_1_by_1')(green)\n",
    "    green = UpSampling2D(size=8,interpolation='bilinear',name='green_upsampling')(green)\n",
    "    # base + red + yellow + blue + green\n",
    "    return tf.keras.layers.concatenate([base,red,yellow,blue,green])\n",
    "\n",
    "def last_conv_module(input_layer):\n",
    "    X = pyramid_feature_maps(input_layer)\n",
    "    X = Convolution2D(filters=3,kernel_size=3,padding='same',name='last_conv_3_by_3')(X)\n",
    "    X = BatchNormalization(name='last_conv_3_by_3_batch_norm')(X)\n",
    "    X = Activation('sigmoid',name='last_conv_relu')(X)\n",
    "    X = tf.keras.layers.Flatten(name='last_conv_flatten')(X)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U5pcJ2TL-xyB"
   },
   "outputs": [],
   "source": [
    "input_layer = tf.keras.Input(shape=np.squeeze(train_imgs[0]).shape,name='input')\n",
    "output_layer = last_conv_module(input_layer)\n",
    "model = tf.keras.Model(inputs=input_layer,outputs=output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "purgPMLr-6BD",
    "outputId": "f762edc7-d262-4174-f136-5334117fdb84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 256, 256, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " block_1_a (Conv2D)             (None, 256, 256, 32  128         ['input[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block_1_batch_norm_a (BatchNor  (None, 256, 256, 32  128        ['block_1_a[0][0]']              \n",
      " malization)                    )                                                                 \n",
      "                                                                                                  \n",
      " block_1_leakyrelu_a (LeakyReLU  (None, 256, 256, 32  0          ['block_1_batch_norm_a[0][0]']   \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " block_1_b (Conv2D)             (None, 256, 256, 32  9248        ['block_1_leakyrelu_a[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block_1_batch_norm_b (BatchNor  (None, 256, 256, 32  128        ['block_1_b[0][0]']              \n",
      " malization)                    )                                                                 \n",
      "                                                                                                  \n",
      " block_1_leakyrelu_b (LeakyReLU  (None, 256, 256, 32  0          ['block_1_batch_norm_b[0][0]']   \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " block_1_c (Conv2D)             (None, 256, 256, 64  2112        ['block_1_leakyrelu_b[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block_1_skip_conv (Conv2D)     (None, 256, 256, 64  1792        ['input[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block_1_batch_norm_c (BatchNor  (None, 256, 256, 64  256        ['block_1_c[0][0]']              \n",
      " malization)                    )                                                                 \n",
      "                                                                                                  \n",
      " block_1_batch_norm_skip_conv (  (None, 256, 256, 64  256        ['block_1_skip_conv[0][0]']      \n",
      " BatchNormalization)            )                                                                 \n",
      "                                                                                                  \n",
      " block_1_add (Add)              (None, 256, 256, 64  0           ['block_1_batch_norm_c[0][0]',   \n",
      "                                )                                 'block_1_batch_norm_skip_conv[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " block_1_relu (ReLU)            (None, 256, 256, 64  0           ['block_1_add[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block_2_a (Conv2D)             (None, 256, 256, 64  4160        ['block_1_relu[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block_2_batch_norm_a (BatchNor  (None, 256, 256, 64  256        ['block_2_a[0][0]']              \n",
      " malization)                    )                                                                 \n",
      "                                                                                                  \n",
      " block_2_leakyrelu_a (LeakyReLU  (None, 256, 256, 64  0          ['block_2_batch_norm_a[0][0]']   \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " block_2_b (Conv2D)             (None, 256, 256, 64  36928       ['block_2_leakyrelu_a[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block_2_batch_norm_b (BatchNor  (None, 256, 256, 64  256        ['block_2_b[0][0]']              \n",
      " malization)                    )                                                                 \n",
      "                                                                                                  \n",
      " block_2_leakyrelu_b (LeakyReLU  (None, 256, 256, 64  0          ['block_2_batch_norm_b[0][0]']   \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " block_2_c (Conv2D)             (None, 256, 256, 12  8320        ['block_2_leakyrelu_b[0][0]']    \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " block_2_skip_conv (Conv2D)     (None, 256, 256, 12  73856       ['block_1_relu[0][0]']           \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " block_2_batch_norm_c (BatchNor  (None, 256, 256, 12  512        ['block_2_c[0][0]']              \n",
      " malization)                    8)                                                                \n",
      "                                                                                                  \n",
      " block_2_batch_norm_skip_conv (  (None, 256, 256, 12  512        ['block_2_skip_conv[0][0]']      \n",
      " BatchNormalization)            8)                                                                \n",
      "                                                                                                  \n",
      " block_2_add (Add)              (None, 256, 256, 12  0           ['block_2_batch_norm_c[0][0]',   \n",
      "                                8)                                'block_2_batch_norm_skip_conv[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " block_2_relu (ReLU)            (None, 256, 256, 12  0           ['block_2_add[0][0]']            \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " block_3_a (Conv2D)             (None, 256, 256, 12  16512       ['block_2_relu[0][0]']           \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " block_3_batch_norm_a (BatchNor  (None, 256, 256, 12  512        ['block_3_a[0][0]']              \n",
      " malization)                    8)                                                                \n",
      "                                                                                                  \n",
      " block_3_leakyrelu_a (LeakyReLU  (None, 256, 256, 12  0          ['block_3_batch_norm_a[0][0]']   \n",
      " )                              8)                                                                \n",
      "                                                                                                  \n",
      " block_3_b (Conv2D)             (None, 256, 256, 12  147584      ['block_3_leakyrelu_a[0][0]']    \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " block_3_batch_norm_b (BatchNor  (None, 256, 256, 12  512        ['block_3_b[0][0]']              \n",
      " malization)                    8)                                                                \n",
      "                                                                                                  \n",
      " block_3_leakyrelu_b (LeakyReLU  (None, 256, 256, 12  0          ['block_3_batch_norm_b[0][0]']   \n",
      " )                              8)                                                                \n",
      "                                                                                                  \n",
      " block_3_c (Conv2D)             (None, 256, 256, 25  33024       ['block_3_leakyrelu_b[0][0]']    \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " block_3_skip_conv (Conv2D)     (None, 256, 256, 25  295168      ['block_2_relu[0][0]']           \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " block_3_batch_norm_c (BatchNor  (None, 256, 256, 25  1024       ['block_3_c[0][0]']              \n",
      " malization)                    6)                                                                \n",
      "                                                                                                  \n",
      " block_3_batch_norm_skip_conv (  (None, 256, 256, 25  1024       ['block_3_skip_conv[0][0]']      \n",
      " BatchNormalization)            6)                                                                \n",
      "                                                                                                  \n",
      " block_3_add (Add)              (None, 256, 256, 25  0           ['block_3_batch_norm_c[0][0]',   \n",
      "                                6)                                'block_3_batch_norm_skip_conv[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " block_3_relu (ReLU)            (None, 256, 256, 25  0           ['block_3_add[0][0]']            \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " red_pool (GlobalAveragePooling  (None, 256)         0           ['block_3_relu[0][0]']           \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 1, 1, 256)    0           ['red_pool[0][0]']               \n",
      "                                                                                                  \n",
      " yellow_pool (AveragePooling2D)  (None, 128, 128, 25  0          ['block_3_relu[0][0]']           \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " blue_pool (AveragePooling2D)   (None, 64, 64, 256)  0           ['block_3_relu[0][0]']           \n",
      "                                                                                                  \n",
      " green_pool (AveragePooling2D)  (None, 32, 32, 256)  0           ['block_3_relu[0][0]']           \n",
      "                                                                                                  \n",
      " red_1_by_1 (Conv2D)            (None, 1, 1, 64)     16448       ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " yellow_1_by_1 (Conv2D)         (None, 128, 128, 64  16448       ['yellow_pool[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " blue_1_by_1 (Conv2D)           (None, 64, 64, 64)   16448       ['blue_pool[0][0]']              \n",
      "                                                                                                  \n",
      " green_1_by_1 (Conv2D)          (None, 32, 32, 64)   16448       ['green_pool[0][0]']             \n",
      "                                                                                                  \n",
      " red_upsampling (UpSampling2D)  (None, 256, 256, 64  0           ['red_1_by_1[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " yellow_upsampling (UpSampling2  (None, 256, 256, 64  0          ['yellow_1_by_1[0][0]']          \n",
      " D)                             )                                                                 \n",
      "                                                                                                  \n",
      " blue_upsampling (UpSampling2D)  (None, 256, 256, 64  0          ['blue_1_by_1[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " green_upsampling (UpSampling2D  (None, 256, 256, 64  0          ['green_1_by_1[0][0]']           \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 256, 256, 51  0           ['block_3_relu[0][0]',           \n",
      "                                2)                                'red_upsampling[0][0]',         \n",
      "                                                                  'yellow_upsampling[0][0]',      \n",
      "                                                                  'blue_upsampling[0][0]',        \n",
      "                                                                  'green_upsampling[0][0]']       \n",
      "                                                                                                  \n",
      " last_conv_3_by_3 (Conv2D)      (None, 256, 256, 3)  13827       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " last_conv_3_by_3_batch_norm (B  (None, 256, 256, 3)  12         ['last_conv_3_by_3[0][0]']       \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " last_conv_relu (Activation)    (None, 256, 256, 3)  0           ['last_conv_3_by_3_batch_norm[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " last_conv_flatten (Flatten)    (None, 196608)       0           ['last_conv_relu[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 713,839\n",
      "Trainable params: 711,145\n",
      "Non-trainable params: 2,694\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "amuUJ6Ht-_yo"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),loss='mse')\n",
    "model.fit(np.array(train_imgs,dtype='float16'),np.array(train_masks,dtype='float16'),\n",
    "          validation_data=(np.array(valid_imgs,dtype='float16'),np.array(valid_masks,dtype='float16')),         \n",
    "          epochs=20,steps_per_epoch=297,verbose=1,batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZJL7iwvN_GJS"
   },
   "outputs": [],
   "source": [
    "tf.keras.models.save_model(model,'/best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oi4HxYrD_La-"
   },
   "outputs": [],
   "source": [
    "pred_masks = model.predict(np.array(valid_imgs,dtype='float16'))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "PSPNet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
